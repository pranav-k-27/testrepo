{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mYH5-jW6BYeW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Zelestra X AWS ML Ascend Challenge - Second Edition - Phase 2"
      ],
      "metadata": {
        "id": "W9bPj4VbBri2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pvlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i4XjolwIGwW",
        "outputId": "e9f2dd93-e3f8-42e6-da22-37d8d9d6d939"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pvlib in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from pvlib) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from pvlib) (2.2.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from pvlib) (2025.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pvlib) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from pvlib) (1.15.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from pvlib) (3.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->pvlib) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->pvlib) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pvlib) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pvlib) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pvlib) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pvlib) (2025.6.15)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->pvlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EDA, Feture Engineering, Loss calculation, Theoratical and Actual generation calculations"
      ],
      "metadata": {
        "id": "dldlnA9zCXWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardized imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pvlib\n",
        "from datetime import datetime\n",
        "from typing import Dict, Tuple, Optional\n",
        "\n",
        "# Constants\n",
        "PLANT_DC_CAPACITY_KW = 45600\n",
        "TEMP_COEFF = -0.004\n",
        "STC_TEMP = 25\n",
        "INTERVAL_HOURS = 0.25\n",
        "\n",
        "class SolarPlantAnalysis:\n",
        "    def __init__(self, filepath: str):\n",
        "        \"\"\"Initialize with data loading and validation\"\"\"\n",
        "        self.data = self._load_data(filepath)\n",
        "        self._validate_data()\n",
        "        self._clean_data()\n",
        "\n",
        "    def _load_data(self, filepath: str) -> pd.DataFrame:\n",
        "        \"\"\"Load and preprocess data with error handling\"\"\"\n",
        "        try:\n",
        "            df = pd.read_csv(filepath)\n",
        "            df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "            df = df.set_index('datetime').sort_index()\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error loading data: {str(e)}\")\n",
        "\n",
        "    def _validate_data(self):\n",
        "        \"\"\"Validate critical columns and values\"\"\"\n",
        "        required_cols = ['meteorolgicas_em_03_02_gii', 'inversores_ctin03_inv_03_03_p']\n",
        "        missing = [col for col in required_cols if col not in self.data.columns]\n",
        "        if missing:\n",
        "            raise ValueError(f\"Missing required columns: {missing}\")\n",
        "\n",
        "        # Check for negative irradiance values\n",
        "        irrad_cols = [col for col in self.data.columns if 'gii' in col]\n",
        "        for col in irrad_cols:\n",
        "            neg_count = (self.data[col] < 0).sum()\n",
        "            if neg_count > 0:\n",
        "                print(f\"Warning: {neg_count} negative values in {col}\")\n",
        "\n",
        "    def _clean_data(self):\n",
        "        \"\"\"Clean and prepare data\"\"\"\n",
        "        # Drop unnecessary columns\n",
        "        cols_to_drop = [\n",
        "            'seguidores_ct03_gcu031_t0308035_workingmode',\n",
        "            'seguidores_ct08_gcu081_t0808029_workingmode'\n",
        "        ]\n",
        "        self.data = self.data.drop(columns=[c for c in cols_to_drop if c in self.data.columns])\n",
        "\n",
        "        # Fill missing values\n",
        "        self.data = self.data.fillna(0)\n",
        "\n",
        "        # Add derived columns\n",
        "        self.data['hour'] = self.data.index.hour\n",
        "        self.data['month'] = self.data.index.month\n",
        "\n",
        "        if 'inverter_id' in self.data.columns:\n",
        "            self.data['INVERTER'] = self.data['inverter_id']\n",
        "        elif 'inv_name' in self.data.columns:\n",
        "            self.data['INVERTER'] = self.data['inv_name']\n",
        "\n",
        "    def calculate_theoretical_power(self) -> pd.DataFrame:\n",
        "        \"\"\"Calculate theoretical power output\"\"\"\n",
        "        # Mean POA irradiance\n",
        "        poa_cols = [c for c in self.data.columns if \"gii\" in c and \"rear\" not in c]\n",
        "        self.data[\"G_POA\"] = self.data[poa_cols].mean(axis=1)\n",
        "\n",
        "        # Module temperature\n",
        "        if \"celulas_ctin03_cc_03_1_t_mod\" in self.data.columns:\n",
        "            self.data[\"T_mod\"] = self.data[\"celulas_ctin03_cc_03_1_t_mod\"]\n",
        "        else:\n",
        "            amb_cols = [c for c in self.data.columns if \"t_amb\" in c]\n",
        "            self.data[\"T_mod\"] = self.data[amb_cols].mean(axis=1)\n",
        "\n",
        "        # Theoretical power calculation\n",
        "        self.data[\"P_theoretical_kW\"] = (\n",
        "            self.data[\"G_POA\"] * PLANT_DC_CAPACITY_KW / 1000 *\n",
        "            (1 + TEMP_COEFF * (self.data[\"T_mod\"] - STC_TEMP)))\n",
        "        self.data[\"P_theoretical_kW\"] = self.data[\"P_theoretical_kW\"].clip(lower=0)\n",
        "\n",
        "        # Theoretical energy\n",
        "        self.data[\"E_theoretical_kWh\"] = self.data[\"P_theoretical_kW\"] * INTERVAL_HOURS\n",
        "        self.data[\"P_theoretical_MW\"] = self.data[\"P_theoretical_kW\"] / 1000\n",
        "        self.data[\"P_theoretical_energy_MWh\"] = self.data[\"E_theoretical_kWh\"] / 1000\n",
        "        return self.data\n",
        "\n",
        "    def add_advanced_loss_features(self):\n",
        "        # Use self.data instead of df\n",
        "        gamma1 = -0.0045\n",
        "        gamma2 = -0.0001\n",
        "        temp_diff = self.data['T_mod_avg'] - 25\n",
        "        self.data['temp_loss_frac_adv'] = (-gamma1 * temp_diff + gamma2 * temp_diff**2).clip(0)\n",
        "        self.data['temp_loss_MWh_adv'] = self.data['temp_loss_frac_adv'] * self.data['P_theoretical_energy_MWh']\n",
        "        # String mismatch model using all string current columns\n",
        "        string_current_cols = [col for col in df.columns if '_pv_i' in col]\n",
        "        if string_current_cols:\n",
        "            df['string_current_mean'] = df[string_current_cols].mean(axis=1)\n",
        "            df['string_current_std'] = df[string_current_cols].std(axis=1)\n",
        "            df['string_mismatch_loss_frac'] = (\n",
        "                df['string_current_std'] / (df['string_current_mean'] + 1e-6)\n",
        "            ).clip(0, 1)\n",
        "            df['string_mismatch_loss_MWh'] = df['string_mismatch_loss_frac'] * df['P_theoretical_energy_MWh']\n",
        "        return df\n",
        "\n",
        "    def calculate_actual_power(self) -> pd.DataFrame:\n",
        "        \"\"\"Calculate actual power from inverters\"\"\"\n",
        "        # Plant-level actual power\n",
        "        inv_cols = ['inversores_ctin03_inv_03_03_p', 'inversores_ctin08_inv_08_08_p']\n",
        "        self.data['actual_plant_power_MW'] = self.data[inv_cols].sum(axis=1)\n",
        "\n",
        "        # Individual inverter power\n",
        "        self.data['actual_inv1_MW'] = self.data['inversores_ctin03_inv_03_03_p']\n",
        "        self.data['actual_inv2_MW'] = self.data['inversores_ctin08_inv_08_08_p']\n",
        "\n",
        "        # Energy calculations (15-min intervals)\n",
        "        self.data['actual_plant_energy_MWh'] = self.data['actual_plant_power_MW'] * INTERVAL_HOURS\n",
        "        self.data['actual_inv1_energy_MWh'] = self.data['actual_inv1_MW'] * INTERVAL_HOURS\n",
        "        self.data['actual_inv2_energy_MWh'] = self.data['actual_inv2_MW'] * INTERVAL_HOURS\n",
        "\n",
        "        return self.data\n",
        "\n",
        "    def calculate_performance_ratio(self) -> pd.DataFrame:\n",
        "        \"\"\"Calculate performance ratio (PR)\"\"\"\n",
        "        if 'P_theoretical_energy_MWh' not in self.data.columns:\n",
        "            self.calculate_theoretical_power()\n",
        "\n",
        "        # Calculate PR (actual/theoretical)\n",
        "        self.data['PR'] = (self.data['actual_plant_energy_MWh'] /\n",
        "                          self.data['P_theoretical_energy_MWh']).clip(0, 1.2)\n",
        "        return self.data\n",
        "\n",
        "    def calculate_advanced_temp_loss(self):\n",
        "        \"\"\"Advanced temperature loss model with quadratic term.\"\"\"\n",
        "        gamma1 = -0.0045  # linear term\n",
        "        gamma2 = -0.0001  # quadratic term (tune as needed)\n",
        "        temp_diff = self.data['T_mod'] - 25\n",
        "        self.data['temp_loss_frac_adv'] = (-gamma1 * temp_diff + gamma2 * temp_diff**2).clip(0)\n",
        "        self.data['temp_loss_MWh_adv'] = self.data['temp_loss_frac_adv'] * self.data['P_theoretical_energy_MWh']\n",
        "\n",
        "    def calculate_advanced_string_mismatch_loss(self):\n",
        "        \"\"\"Data-driven string mismatch loss using string current spread.\"\"\"\n",
        "        string_current_cols = [col for col in self.data.columns if '_pv_i' in col]\n",
        "        if string_current_cols:\n",
        "            self.data['string_current_mean'] = self.data[string_current_cols].mean(axis=1)\n",
        "            self.data['string_current_std'] = self.data[string_current_cols].std(axis=1)\n",
        "            self.data['string_mismatch_loss_frac'] = (\n",
        "                self.data['string_current_std'] / (self.data['string_current_mean'] + 1e-6)\n",
        "            ).clip(0, 1)\n",
        "            self.data['string_mismatch_loss_MWh'] = (\n",
        "                self.data['string_mismatch_loss_frac'] * self.data['P_theoretical_energy_MWh']\n",
        "            )\n",
        "        else:\n",
        "            self.data['string_current_mean'] = 0\n",
        "            self.data['string_current_std'] = 0\n",
        "            self.data['string_mismatch_loss_frac'] = 0\n",
        "            self.data['string_mismatch_loss_MWh'] = 0\n",
        "\n",
        "    def calculate_losses(self) -> Dict[str, float]:\n",
        "        \"\"\"Calculate different types of losses (includes advanced models).\"\"\"\n",
        "        losses = {}\n",
        "\n",
        "        # Cloud loss (using clear-sky model)\n",
        "        if all(col in self.data.columns for col in ['meteorolgicas_em_03_02_ghi', 'meteorolgicas_em_08_01_ghi']):\n",
        "            self.data['ghi_measured'] = self.data[['meteorolgicas_em_03_02_ghi', 'meteorolgicas_em_08_01_ghi']].mean(axis=1)\n",
        "            location = pvlib.location.Location(\n",
        "                latitude=38.0006, longitude=-1.3344,\n",
        "                tz='Europe/Madrid', altitude=0\n",
        "            )\n",
        "            clearsky = location.get_clearsky(self.data.index, model='ineichen')\n",
        "            self.data['ghi_clearsky'] = clearsky['ghi']\n",
        "            self.data['cloud_loss_frac'] = (1 - (self.data['ghi_measured'] / self.data['ghi_clearsky'])).clip(0, 1)\n",
        "            self.data['cloud_loss_MWh'] = self.data['cloud_loss_frac'] * self.data['P_theoretical_energy_MWh']\n",
        "            losses['cloud_loss'] = self.data['cloud_loss_MWh'].mean()\n",
        "\n",
        "        # Temperature loss (advanced)\n",
        "        self.calculate_advanced_temp_loss()\n",
        "        self.data['temp_loss_MWh'] = self.data['temp_loss_MWh_adv']\n",
        "        losses['temp_loss'] = self.data['temp_loss_MWh'].mean()\n",
        "\n",
        "\n",
        "        # Soiling loss (using GII ratio between sensors)\n",
        "        if all(col in self.data.columns for col in ['meteorolgicas_em_08_01_gii', 'meteorolgicas_em_03_02_gii']):\n",
        "            self.data['soiling_ratio'] = (\n",
        "                self.data['meteorolgicas_em_08_01_gii'] /\n",
        "                self.data['meteorolgicas_em_03_02_gii']\n",
        "            ).clip(0.7, 1.1)\n",
        "            self.data['soiling_loss_frac'] = (1 - self.data['soiling_ratio']).clip(0)\n",
        "            self.data['soiling_loss_MWh'] = self.data['soiling_loss_frac'] * self.data['P_theoretical_energy_MWh']\n",
        "            losses['soiling_loss'] = self.data['soiling_loss_MWh'].mean()\n",
        "\n",
        "        # --- Advanced string mismatch loss ---\n",
        "        self.calculate_advanced_string_mismatch_loss()\n",
        "        self.data['mismatch_loss_MWh'] = self.data['string_mismatch_loss_MWh']\n",
        "        losses['mismatch_loss'] = self.data['mismatch_loss_MWh'].mean()\n",
        "\n",
        "        # Tracker loss (empirical or with data)\n",
        "        tracker_loss_frac = 0.005\n",
        "        self.data['tracker_loss_MWh'] = tracker_loss_frac * self.data['P_theoretical_energy_MWh']\n",
        "        losses['tracker_loss'] = self.data['tracker_loss_MWh'].mean()\n",
        "\n",
        "        # High wind loss (empirical or with wind speed)\n",
        "        if 'wind_speed' in self.data.columns:\n",
        "            stow = self.data['wind_speed'] > 18\n",
        "            high_wind_loss_frac = 0.01\n",
        "            self.data['high_wind_loss'] = np.where(stow, high_wind_loss_frac * self.data['P_theoretical_energy_MWh'], 0)\n",
        "            losses['high_wind_loss'] = self.data['high_wind_loss'].mean()\n",
        "        else:\n",
        "            self.data['high_wind_loss'] = 0\n",
        "            losses['high_wind_loss'] = 0\n",
        "\n",
        "        # Humidity loss (empirical or with humidity data)\n",
        "        if 'humidity' in self.data.columns:\n",
        "            high_humidity = self.data['humidity'] > 90\n",
        "            humidity_loss_frac = 0.005\n",
        "            self.data['humidity_loss'] = np.where(high_humidity, humidity_loss_frac * self.data['P_theoretical_energy_MWh'], 0)\n",
        "            losses['humidity_loss'] = self.data['humidity_loss'].mean()\n",
        "        else:\n",
        "            self.data['humidity_loss'] = 0\n",
        "            losses['humidity_loss'] = 0\n",
        "\n",
        "        # Inverter loss (fixed 2% of theoretical)\n",
        "        inverter_loss_frac = 0.02\n",
        "        self.data['inverter_loss_MWh'] = inverter_loss_frac * self.data['P_theoretical_energy_MWh']\n",
        "        losses['inverter_loss'] = self.data['inverter_loss_MWh'].mean()\n",
        "\n",
        "        # DC wiring loss (fixed 1% of theoretical)\n",
        "        dc_wiring_loss_frac = 0.01\n",
        "        self.data['dc_wiring_loss_MWh'] = dc_wiring_loss_frac * self.data['P_theoretical_energy_MWh']\n",
        "        losses['dc_wiring_loss'] = self.data['dc_wiring_loss_MWh'].mean()\n",
        "\n",
        "        # Shading loss (fixed 1% of theoretical)\n",
        "        shading_loss_frac = 0.01\n",
        "        self.data['shading_loss_MWh'] = shading_loss_frac * self.data['P_theoretical_energy_MWh']\n",
        "        losses['shading_loss'] = self.data['shading_loss_MWh'].mean()\n",
        "\n",
        "\n",
        "        known_losses = [\n",
        "            'cloud_loss_MWh', 'temp_loss_MWh', 'soiling_loss_MWh', 'shading_loss_MWh',\n",
        "            'inverter_loss_MWh', 'dc_wiring_loss_MWh', 'mismatch_loss_MWh',\n",
        "            'tracker_loss_MWh', 'high_wind_loss', 'humidity_loss'\n",
        "        ]\n",
        "        valid_known = [col for col in known_losses if col in self.data.columns]\n",
        "        self.data['total_known_losses'] = self.data[valid_known].sum(axis=1)\n",
        "        self.data['unexplained_loss_MWh'] = (\n",
        "            self.data['P_theoretical_energy_MWh'] -\n",
        "            self.data['actual_plant_energy_MWh'] -\n",
        "            self.data['total_known_losses']\n",
        "        ).clip(0)\n",
        "        losses['unexplained_loss'] = self.data['unexplained_loss_MWh'].mean()\n",
        "        return losses\n",
        "\n",
        "\n",
        "    def plot_comparison(self, freq: str = 'W', show_inverters: bool = False):\n",
        "        \"\"\"Plot comparison between theoretical and actual power\"\"\"\n",
        "        resampled = self.data.resample(freq).mean()\n",
        "        plt.figure(figsize=(15, 6))\n",
        "        resampled['P_theoretical_MW'].plot(\n",
        "            label='Theoretical Power', color='black', linestyle='--')\n",
        "        resampled['actual_plant_power_MW'].plot(\n",
        "            label='Actual Plant Power', color='green')\n",
        "        if show_inverters:\n",
        "            resampled['actual_inv1_MW'].plot(\n",
        "                label='Inverter 1', color='blue', alpha=0.7)\n",
        "            resampled['actual_inv2_MW'].plot(\n",
        "                label='Inverter 2', color='red', alpha=0.7)\n",
        "        plt.title(f'Theoretical vs Actual Power ({freq} Average)')\n",
        "        plt.ylabel('Power (MW)')\n",
        "        plt.xlabel('Date')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_loss_breakdown(self, freq: str = 'W'):\n",
        "        \"\"\"Plot stacked area chart of different loss types\"\"\"\n",
        "        loss_cols = [\n",
        "            'cloud_loss_MWh', 'temp_loss_MWh', 'soiling_loss_MWh', 'shading_loss_MWh',\n",
        "            'inverter_loss_MWh', 'dc_wiring_loss_MWh', 'mismatch_loss_MWh',\n",
        "            'tracker_loss_MWh', 'high_wind_loss', 'humidity_loss', 'unexplained_loss_MWh'\n",
        "        ]\n",
        "        # Ensure all columns exist\n",
        "        valid_loss_cols = [col for col in loss_cols if col in self.data.columns]\n",
        "        if not valid_loss_cols:\n",
        "            print(\"No loss data available. Run calculate_losses() first.\")\n",
        "            return\n",
        "        loss_data = self.data[valid_loss_cols].resample(freq).sum()\n",
        "        plt.figure(figsize=(15, 6))\n",
        "        ax = loss_data.plot.area(\n",
        "            stacked=True,\n",
        "            color=[\n",
        "                'skyblue', 'orange', 'khaki', 'gray', 'violet', 'gold', 'purple',\n",
        "                'olive', 'lightgreen', 'lightblue', 'lightcoral'\n",
        "            ]\n",
        "        )\n",
        "        # Add theoretical and actual lines\n",
        "        theoretical = self.data['P_theoretical_energy_MWh'].resample(freq).sum()\n",
        "        actual = self.data['actual_plant_energy_MWh'].resample(freq).sum()\n",
        "        theoretical.plot(ax=ax, color='black', linestyle='--', label='Theoretical')\n",
        "        actual.plot(ax=ax, color='green', linewidth=2, label='Actual')\n",
        "        plt.title(f'Energy Loss Breakdown ({freq} Total)')\n",
        "        plt.ylabel('Energy (MWh)')\n",
        "        plt.xlabel('Date')\n",
        "        plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def analyze_performance_ratio(self):\n",
        "        \"\"\"Analyze performance ratio by different conditions\"\"\"\n",
        "        if 'PR' not in self.data.columns:\n",
        "            self.calculate_performance_ratio()\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "        if 'hour' in self.data.columns:\n",
        "            self.data.groupby('hour')['PR'].mean().plot(\n",
        "                ax=axes[0,0], marker='o', title='PR by Hour of Day')\n",
        "            axes[0,0].set_ylim(0, 1.1)\n",
        "        if 'T_mod' in self.data.columns:\n",
        "            temp_bins = [0, 20, 40, 60, 80]\n",
        "            self.data['temp_range'] = pd.cut(self.data['T_mod'], bins=temp_bins)\n",
        "            self.data.groupby('temp_range')['PR'].mean().plot(\n",
        "                kind='bar', ax=axes[0,1], title='PR by Temperature Range')\n",
        "            axes[0,1].set_ylim(0, 1.1)\n",
        "        if 'PR' in self.data.columns:\n",
        "            self.data['PR'].hist(ax=axes[1,0], bins=30)\n",
        "            axes[1,0].set_title('PR Distribution')\n",
        "            self.data['PR'].resample('W').mean().plot(\n",
        "                ax=axes[1,1], title='Weekly PR Trend')\n",
        "            axes[1,1].axhline(0.8, color='red', linestyle='--')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(\"\\nPerformance Ratio Statistics:\")\n",
        "        print(f\"Mean PR: {self.data['PR'].mean():.3f}\")\n",
        "        print(f\"Median PR: {self.data['PR'].median():.3f}\")\n",
        "        print(f\"Minimum PR: {self.data['PR'].min():.3f}\")\n",
        "        print(f\"Maximum PR: {self.data['PR'].max():.3f}\")\n",
        "\n",
        "    def plot_loss_pie_and_trends(self, freq: str = 'W'):\n",
        "        \"\"\"Plot pie chart of average losses and time series of loss trends (highlight unexplained loss).\"\"\"\n",
        "        # Loss columns to include\n",
        "        loss_cols = [\n",
        "            'cloud_loss_MWh', 'temp_loss_MWh', 'soiling_loss_MWh', 'shading_loss_MWh',\n",
        "            'inverter_loss_MWh', 'dc_wiring_loss_MWh', 'mismatch_loss_MWh',\n",
        "            'tracker_loss_MWh', 'high_wind_loss', 'humidity_loss', 'unexplained_loss_MWh'\n",
        "        ]\n",
        "        valid_loss_cols = [col for col in loss_cols if col in self.data.columns]\n",
        "\n",
        "        # Pie chart: average losses\n",
        "        avg_losses = [self.data[col].mean() for col in valid_loss_cols]\n",
        "\n",
        "        # Assign colors, with unexplained_loss_MWh as red\n",
        "        base_colors = [\n",
        "            'skyblue', 'orange', 'limegreen', 'gray', 'violet', 'gold', 'purple',\n",
        "            'olive', 'lightgreen', 'lightblue'\n",
        "        ]\n",
        "        pie_colors = []\n",
        "        for col in valid_loss_cols:\n",
        "            if col == 'unexplained_loss_MWh':\n",
        "                pie_colors.append('red')\n",
        "            else:\n",
        "                # Cycle through base_colors\n",
        "                pie_colors.append(base_colors.pop(0) if base_colors else 'gray')\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.pie(avg_losses, labels=valid_loss_cols, colors=pie_colors, autopct='%1.1f%%', startangle=140)\n",
        "        plt.title(\"Average Losses Contribution (Pie Chart)\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Time series of each loss (unchanged)\n",
        "        loss_data = self.data[valid_loss_cols].resample(freq).sum()\n",
        "        plt.figure(figsize=(15, 6))\n",
        "        for col in valid_loss_cols:\n",
        "            plt.plot(loss_data.index, loss_data[col], label=col)\n",
        "        plt.title(f\"Losses Over Time ({freq} totals)\")\n",
        "        plt.ylabel(\"Loss (MWh)\")\n",
        "        plt.xlabel(\"Date\")\n",
        "        plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Correlation heatmap for losses and main metrics\n",
        "        corr_cols = valid_loss_cols + [\n",
        "            'G_POA', 'T_mod', 'actual_plant_power_MW', 'PR'\n",
        "        ]\n",
        "        corr_cols = [col for col in corr_cols if col in self.data.columns]\n",
        "        corr = self.data[corr_cols].corr()\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
        "        plt.title(\"Correlation Heatmap: Losses and Key Metrics\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def add_loss_flags(self, threshold_dict=None):\n",
        "        \"\"\"\n",
        "        Adds boolean flag columns for each loss, per interval.\n",
        "        threshold_dict: dict of {loss_col: threshold}, if None, use mean+std as thresholds\n",
        "        \"\"\"\n",
        "        loss_cols = [\n",
        "            'cloud_loss_MWh', 'temp_loss_MWh', 'soiling_loss_MWh', 'shading_loss_MWh',\n",
        "            'inverter_loss_MWh', 'dc_wiring_loss_MWh', 'mismatch_loss_MWh',\n",
        "            'tracker_loss_MWh', 'high_wind_loss', 'humidity_loss', 'unexplained_loss_MWh'\n",
        "        ]\n",
        "        for col in loss_cols:\n",
        "            if col in self.data.columns:\n",
        "                if threshold_dict and col in threshold_dict:\n",
        "                    thresh = threshold_dict[col]\n",
        "                else:\n",
        "                    # Default: anything above mean+std is flagged\n",
        "                    thresh = self.data[col].mean() + self.data[col].std()\n",
        "                self.data[col + '_flag'] = (self.data[col] > thresh).astype(int)\n",
        "\n",
        "    def get_loss_flags_table(self, cols=None):\n",
        "        \"\"\"\n",
        "        Returns a DataFrame with datetime, asset columns, and boolean loss flags.\n",
        "        \"\"\"\n",
        "        if cols is None:\n",
        "            cols = ['datetime', 'Zone', 'INVERTER', 'String']  # update as per your data structure\n",
        "        flag_cols = [c for c in self.data.columns if c.endswith('_flag')]\n",
        "        out_cols = [c for c in cols if c in self.data.reset_index().columns] + flag_cols\n",
        "        return self.data.reset_index()[out_cols]\n",
        "\n",
        "    def aggregate_losses(self, by=['INVERTER'], freq='D'):\n",
        "        \"\"\"\n",
        "        Aggregates losses by asset (e.g., INVERTER, String) and time (e.g., daily).\n",
        "        Returns a DataFrame ready for reporting (sum of each loss per group).\n",
        "        \"\"\"\n",
        "        loss_cols = [\n",
        "            'cloud_loss_MWh', 'temp_loss_MWh', 'soiling_loss_MWh', 'shading_loss_MWh',\n",
        "            'inverter_loss_MWh', 'dc_wiring_loss_MWh', 'mismatch_loss_MWh',\n",
        "            'tracker_loss_MWh', 'high_wind_loss', 'humidity_loss', 'unexplained_loss_MWh'\n",
        "        ]\n",
        "        group_cols = []\n",
        "        if freq:\n",
        "            group_cols.append(pd.Grouper(freq=freq))\n",
        "        for asset_col in by:\n",
        "            if asset_col in self.data.columns:\n",
        "                group_cols.append(asset_col)\n",
        "        valid_loss_cols = [col for col in loss_cols if col in self.data.columns]\n",
        "        agg = self.data.groupby(group_cols)[valid_loss_cols].sum().reset_index()\n",
        "        return agg\n",
        "\n",
        "    def asset_ranking(self, loss_type='soiling_loss_MWh', level='INVERTER', top_n=5):\n",
        "        \"\"\"\n",
        "        Ranks assets by mean loss, e.g., best/worst inverter or string.\n",
        "        \"\"\"\n",
        "        if loss_type not in self.data.columns or level not in self.data.columns:\n",
        "            print(f\"{loss_type} or {level} not in data!\")\n",
        "            return None\n",
        "        ranking = self.data.groupby(level)[loss_type].mean().sort_values(ascending=False)\n",
        "        print(f\"Top {top_n} assets with highest {loss_type}:\")\n",
        "        print(ranking.head(top_n))\n",
        "        print(f\"\\nTop {top_n} assets with lowest {loss_type}:\")\n",
        "        print(ranking.tail(top_n))\n",
        "        return ranking\n",
        "\n",
        "\n",
        "\n",
        "        # --- Correlation Heatmap: Losses and Key Metrics ---\n",
        "        # Select columns for correlation (add more as needed)\n",
        "        corr_cols = valid_loss_cols + [\n",
        "            'G_POA', 'T_mod', 'actual_plant_power_MW', 'PR'\n",
        "        ]\n",
        "        corr_cols = [col for col in corr_cols if col in self.data.columns]\n",
        "        corr = self.data[corr_cols].corr()\n",
        "\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
        "        plt.title(\"Correlation Heatmap: Losses and Key Metrics\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_unexplained_vs_operational(self):\n",
        "        \"\"\"Diagnostic plots: unexplained loss vs key operational features\"\"\"\n",
        "        # Example: Temperature\n",
        "        if 'T_mod_avg' in self.data.columns:\n",
        "            sns.scatterplot(x=self.data['T_mod_avg'], y=self.data['unexplained_loss_MWh'])\n",
        "            plt.title('Unexplained Loss vs Module Temperature')\n",
        "            plt.show()\n",
        "        # Example: String current std (string mismatch)\n",
        "        if 'string_current_std' in self.data.columns:\n",
        "            sns.scatterplot(x=self.data['string_current_std'], y=self.data['unexplained_loss_MWh'])\n",
        "            plt.title('Unexplained Loss vs String Current Std')\n",
        "            plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        print(\"Starting solar plant analysis...\")\n",
        "        analysis = SolarPlantAnalysis('/content/drive/MyDrive/Colab_Files/solar hackathon/Dataset 1.csv')\n",
        "        analysis.calculate_theoretical_power()\n",
        "        analysis.calculate_actual_power()\n",
        "        analysis.calculate_performance_ratio()\n",
        "        losses = analysis.calculate_losses()\n",
        "        print(\"\\nAverage Losses (MWh per interval):\")\n",
        "        for loss_type, value in losses.items():\n",
        "            print(f\"{loss_type:15s}: {value:.4f}\")\n",
        "\n",
        "        # Existing plots\n",
        "        analysis.plot_comparison(freq='W', show_inverters=True)\n",
        "        analysis.plot_loss_breakdown(freq='W')\n",
        "        analysis.analyze_performance_ratio()\n",
        "        analysis.plot_loss_pie_and_trends(freq='W')\n",
        "\n",
        "        # Boolean loss flags for FULL data, export as CSV\n",
        "        analysis.add_loss_flags()\n",
        "        flags_table = analysis.get_loss_flags_table()\n",
        "        flags_table.to_csv(\"boolean_loss_flags_full.csv\", index=False)\n",
        "        print(\"Full Boolean Loss Flags Table saved as boolean_loss_flags_full.csv\")\n",
        "\n",
        "        # Aggregated daily losses by inverter (ensure INVERTER column exists!)\n",
        "        daily_inv_losses = analysis.aggregate_losses(by=['INVERTER'], freq='D')\n",
        "        print(\"\\nSample Daily Losses by Inverter:\")\n",
        "        print(daily_inv_losses.head())\n",
        "\n",
        "        # Asset ranking (ensure soiling_loss_MWh and INVERTER exist!)\n",
        "        analysis.asset_ranking(loss_type='soiling_loss_MWh', level='INVERTER')\n",
        "\n",
        "        print(\"\\nAnalysis completed successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError during analysis: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjOhtat-AA5y",
        "outputId": "4c77c9c1-d0b7-4de1-a082-bd95d5b59367"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting solar plant analysis...\n",
            "\n",
            "Average Losses (MWh per interval):\n",
            "cloud_loss     : 0.5642\n",
            "temp_loss      : 0.0546\n",
            "soiling_loss   : 0.1667\n",
            "mismatch_loss  : 0.3983\n",
            "tracker_loss   : 0.0085\n",
            "high_wind_loss : 0.0000\n",
            "humidity_loss  : 0.0000\n",
            "inverter_loss  : 0.0339\n",
            "dc_wiring_loss : 0.0169\n",
            "shading_loss   : 0.0169\n",
            "unexplained_loss: 0.5951\n",
            "\n",
            "Performance Ratio Statistics:\n",
            "Mean PR: 0.166\n",
            "Median PR: 0.186\n",
            "Minimum PR: 0.000\n",
            "Maximum PR: 1.200\n",
            "Full Boolean Loss Flags Table saved as boolean_loss_flags_full.csv\n",
            "\n",
            "Sample Daily Losses by Inverter:\n",
            "    datetime  cloud_loss_MWh  temp_loss_MWh  soiling_loss_MWh  \\\n",
            "0 2024-10-01       33.953667       8.398847          6.430122   \n",
            "1 2024-10-02       32.204480       7.343832          7.994864   \n",
            "2 2024-10-03       33.694271      13.229612         10.215930   \n",
            "3 2024-10-04       34.253063       9.314687          9.438679   \n",
            "4 2024-10-05       33.738023       8.611242          6.683591   \n",
            "\n",
            "   shading_loss_MWh  inverter_loss_MWh  dc_wiring_loss_MWh  mismatch_loss_MWh  \\\n",
            "0          2.612804           5.225608            2.612804          41.860103   \n",
            "1          2.403381           4.806761            2.403381          38.256305   \n",
            "2          2.844944           5.689888            2.844944          44.877898   \n",
            "3          2.396112           4.792224            2.396112          40.413165   \n",
            "4          2.654688           5.309376            2.654688          44.339138   \n",
            "\n",
            "   tracker_loss_MWh  high_wind_loss  humidity_loss  unexplained_loss_MWh  \n",
            "0          1.306402               0              0            112.520504  \n",
            "1          1.201690               0              0            103.230149  \n",
            "2          1.422472               0              0            120.156476  \n",
            "3          1.198056               0              0             95.176000  \n",
            "4          1.327344               0              0            113.383970  \n",
            "soiling_loss_MWh or INVERTER not in data!\n",
            "\n",
            "Analysis completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analysis.plot_unexplained_vs_operational()"
      ],
      "metadata": {
        "id": "qh5AY0d2BYgx"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Asset ranking Calculations"
      ],
      "metadata": {
        "id": "hUANAWf1Cru2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Allocate plant-level losses to each inverter\n",
        "analysis.data['inv1_frac'] = analysis.data['actual_inv1_MW'] / (analysis.data['actual_plant_power_MW'] + 1e-6)\n",
        "analysis.data['inv2_frac'] = analysis.data['actual_inv2_MW'] / (analysis.data['actual_plant_power_MW'] + 1e-6)\n",
        "\n",
        "analysis.data['unexplained_loss_inv1_MWh'] = analysis.data['unexplained_loss_MWh'] * analysis.data['inv1_frac']\n",
        "analysis.data['unexplained_loss_inv2_MWh'] = analysis.data['unexplained_loss_MWh'] * analysis.data['inv2_frac']\n",
        "\n",
        "# Sum total unexplained loss for each inverter\n",
        "inv1_total = analysis.data['unexplained_loss_inv1_MWh'].sum()\n",
        "inv2_total = analysis.data['unexplained_loss_inv2_MWh'].sum()\n",
        "\n",
        "# Create DataFrame and save as CSV\n",
        "asset_ranking = pd.DataFrame({\n",
        "    'INVERTER': ['inv1', 'inv2'],\n",
        "    'unexplained_loss_MWh': [inv1_total, inv2_total]\n",
        "}).sort_values('unexplained_loss_MWh', ascending=False)\n",
        "\n",
        "asset_ranking.to_csv('asset_ranking_unexplained_loss.csv', index=False)\n",
        "print(\"Asset ranking saved as asset_ranking_unexplained_loss.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iChhavHF9zm",
        "outputId": "9006de13-dd55-4662-a78c-0312abedfd56"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asset ranking saved as asset_ranking_unexplained_loss.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tR4LbW7N0Zv-"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the full analysis.data DataFrame to CSV\n",
        "analysis.data.to_csv(\"full_analysis_data.csv\")\n",
        "print(\"Full analysis DataFrame saved as full_analysis_data.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPDEyt3MJ-tz",
        "outputId": "2c74b364-dd98-4388-e7d6-13662a859d82"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full analysis DataFrame saved as full_analysis_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Asset ranking by all losses"
      ],
      "metadata": {
        "id": "WUS2SA0pGchw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of plant-level losses to allocate and rank\n",
        "loss_types = [\n",
        "    'unexplained_loss_MWh',\n",
        "    'soiling_loss_MWh',\n",
        "    'mismatch_loss_MWh',\n",
        "    'temp_loss_MWh',\n",
        "    'cloud_loss_MWh',\n",
        "    'tracker_loss_MWh',\n",
        "    'high_wind_loss',\n",
        "    'humidity_loss',\n",
        "    'inverter_loss_MWh',\n",
        "    'dc_wiring_loss_MWh',\n",
        "    'shading_loss_MWh'\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Compute inverter fractions (if not already done)\n",
        "analysis.data['inv1_frac'] = analysis.data['actual_inv1_MW'] / (analysis.data['actual_plant_power_MW'] + 1e-6)\n",
        "analysis.data['inv2_frac'] = analysis.data['actual_inv2_MW'] / (analysis.data['actual_plant_power_MW'] + 1e-6)\n",
        "\n",
        "# Prepare ranking results\n",
        "results = {\n",
        "    'INVERTER': ['inv1', 'inv2']\n",
        "}\n",
        "\n",
        "for loss in loss_types:\n",
        "    inv1_col = f'{loss}_inv1'\n",
        "    inv2_col = f'{loss}_inv2'\n",
        "    # Allocate loss proportionally\n",
        "    analysis.data[inv1_col] = analysis.data[loss] * analysis.data['inv1_frac']\n",
        "    analysis.data[inv2_col] = analysis.data[loss] * analysis.data['inv2_frac']\n",
        "    # Sum over all intervals for each inverter\n",
        "    results[loss] = [\n",
        "        analysis.data[inv1_col].sum(),\n",
        "        analysis.data[inv2_col].sum()\n",
        "    ]\n",
        "\n",
        "# Create DataFrame and save as CSV\n",
        "asset_ranking_all = pd.DataFrame(results)\n",
        "asset_ranking_all.to_csv('asset_ranking_all_losses.csv', index=False)\n",
        "print(\"Asset ranking by all losses saved as asset_ranking_all_losses.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLVyXaeZCdlw",
        "outputId": "8b7390dc-eb34-4ab0-d442-e5f4c8ecb8b5"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asset ranking by all losses saved as asset_ranking_all_losses.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Total loss breakdown per inverter"
      ],
      "metadata": {
        "id": "SFcO4yicGk_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load data (change filename if needed)\n",
        "asset_ranking = pd.read_csv('asset_ranking_all_losses.csv')\n",
        "\n",
        "\n",
        "# --- Grouped bar chart ---\n",
        "ax = asset_ranking.set_index('INVERTER')[loss_types].T.plot(\n",
        "    kind='bar',\n",
        "    figsize=(15,7),\n",
        "    width=0.8\n",
        ")\n",
        "plt.title('All Losses by Inverter (Grouped Bar)')\n",
        "plt.ylabel('Total Loss (MWh)')\n",
        "plt.xlabel('Loss Type')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Inverter')\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.show()\n",
        "\n",
        "# --- Stacked bar chart ---\n",
        "ax = asset_ranking.set_index('INVERTER')[loss_types].plot(\n",
        "    kind='bar',\n",
        "    stacked=True,\n",
        "    figsize=(12, 7)\n",
        ")\n",
        "plt.title('Total Loss Breakdown per Inverter (Stacked)')\n",
        "plt.ylabel('Total Loss (MWh)')\n",
        "plt.xlabel('Inverter')\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title='Loss Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vyATKcQfLFhJ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asset_ranking_all.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "876d-XPOLGLG",
        "outputId": "5b8f3dea-ddee-48bb-c106-ac91319ca1cc"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  INVERTER  unexplained_loss_MWh  soiling_loss_MWh  mismatch_loss_MWh  \\\n",
              "0     inv1           5181.324969        700.264260        3138.777690   \n",
              "1     inv2           5215.643516        633.957358        3815.905634   \n",
              "\n",
              "   temp_loss_MWh  cloud_loss_MWh  tracker_loss_MWh  high_wind_loss  \\\n",
              "0     480.098078     2283.299435         72.787167             0.0   \n",
              "1     474.599931     2527.109087         75.046369             0.0   \n",
              "\n",
              "   humidity_loss  inverter_loss_MWh  dc_wiring_loss_MWh  shading_loss_MWh  \n",
              "0            0.0         291.148668          145.574334        145.574334  \n",
              "1            0.0         300.185475          150.092738        150.092738  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97edb46c-48a6-4ba9-87d3-0848d459ba6e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>INVERTER</th>\n",
              "      <th>unexplained_loss_MWh</th>\n",
              "      <th>soiling_loss_MWh</th>\n",
              "      <th>mismatch_loss_MWh</th>\n",
              "      <th>temp_loss_MWh</th>\n",
              "      <th>cloud_loss_MWh</th>\n",
              "      <th>tracker_loss_MWh</th>\n",
              "      <th>high_wind_loss</th>\n",
              "      <th>humidity_loss</th>\n",
              "      <th>inverter_loss_MWh</th>\n",
              "      <th>dc_wiring_loss_MWh</th>\n",
              "      <th>shading_loss_MWh</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>inv1</td>\n",
              "      <td>5181.324969</td>\n",
              "      <td>700.264260</td>\n",
              "      <td>3138.777690</td>\n",
              "      <td>480.098078</td>\n",
              "      <td>2283.299435</td>\n",
              "      <td>72.787167</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>291.148668</td>\n",
              "      <td>145.574334</td>\n",
              "      <td>145.574334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>inv2</td>\n",
              "      <td>5215.643516</td>\n",
              "      <td>633.957358</td>\n",
              "      <td>3815.905634</td>\n",
              "      <td>474.599931</td>\n",
              "      <td>2527.109087</td>\n",
              "      <td>75.046369</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>300.185475</td>\n",
              "      <td>150.092738</td>\n",
              "      <td>150.092738</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97edb46c-48a6-4ba9-87d3-0848d459ba6e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-97edb46c-48a6-4ba9-87d3-0848d459ba6e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-97edb46c-48a6-4ba9-87d3-0848d459ba6e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fb537d61-a6f9-4676-a7ff-df62deadaa9d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb537d61-a6f9-4676-a7ff-df62deadaa9d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fb537d61-a6f9-4676-a7ff-df62deadaa9d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "asset_ranking_all",
              "summary": "{\n  \"name\": \"asset_ranking_all\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"INVERTER\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"inv2\",\n          \"inv1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unexplained_loss_MWh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24.266876925717632,\n        \"min\": 5181.324969195195,\n        \"max\": 5215.643515659984,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          5215.643515659984,\n          5181.324969195195\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"soiling_loss_MWh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46.886060008616276,\n        \"min\": 633.9573580336242,\n        \"max\": 700.2642599840482,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          633.9573580336242,\n          700.2642599840482\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mismatch_loss_MWh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 478.8017613220871,\n        \"min\": 3138.7776898228494,\n        \"max\": 3815.9056343726706,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3815.9056343726706,\n          3138.7776898228494\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temp_loss_MWh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.8877763864959007,\n        \"min\": 474.59993147851645,\n        \"max\": 480.0980775717728,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          474.59993147851645,\n          480.0980775717728\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cloud_loss_MWh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 172.3994578090837,\n        \"min\": 2283.299435438527,\n        \"max\": 2527.1090868179012,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2527.1090868179012,\n          2283.299435438527\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tracker_loss_MWh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5974968660074944,\n        \"min\": 72.78716709659271,\n        \"max\": 75.04636883034902,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          75.04636883034902,\n          72.78716709659271\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high_wind_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"humidity_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inverter_loss_MWh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.389987464029978,\n        \"min\": 291.14866838637084,\n        \"max\": 300.1854753213961,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          300.1854753213961\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dc_wiring_loss_MWh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.194993732014989,\n        \"min\": 145.57433419318542,\n        \"max\": 150.09273766069805,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          150.09273766069805\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shading_loss_MWh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.194993732014989,\n        \"min\": 145.57433419318542,\n        \"max\": 150.09273766069805,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          150.09273766069805\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inverter-level losses, Plant-level losses, Plant-level string mismatch, String mismatch timeseries"
      ],
      "metadata": {
        "id": "sX6BBqCFGvvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load your main data\n",
        "df = pd.read_csv(\"full_analysis_data.csv\")\n",
        "\n",
        "# --- 1. PLANT LEVEL ---\n",
        "loss_cols = [\n",
        "    \"soiling_loss_MWh\", \"cloud_loss_MWh\", \"temp_loss_MWh\", \"tracker_loss_MWh\",\n",
        "    \"inverter_loss_MWh\", \"dc_wiring_loss_MWh\", \"shading_loss_MWh\", \"mismatch_loss_MWh\",\n",
        "    \"high_wind_loss\", \"humidity_loss\", \"unexplained_loss_MWh\"\n",
        "]\n",
        "\n",
        "plant_losses = df[loss_cols].sum().reset_index()\n",
        "plant_losses.columns = [\"loss_type\", \"plant_loss_MWh\"]\n",
        "plant_losses.to_csv(\"plant_level_energy_losses.csv\", index=False)\n",
        "\n",
        "\n",
        "# --- 2. INVERTER LEVEL ---\n",
        "inv_loss_cols = [\n",
        "    \"unexplained_loss_inv1_MWh\",\n",
        "    \"unexplained_loss_inv2_MWh\"\n",
        "]\n",
        "\n",
        "inv_agg = []\n",
        "\n",
        "# Aggregate available inverter loss columns\n",
        "for col in inv_loss_cols:\n",
        "    if col in df.columns:\n",
        "        inv_id = col.split(\"_\")[2]  # e.g. 'inv1', 'inv2'\n",
        "        total = df[col].sum()\n",
        "        inv_agg.append({\n",
        "            \"inverter\": inv_id,\n",
        "            \"loss_type\": \"unexplained_loss\",\n",
        "            \"loss_MWh\": total\n",
        "        })\n",
        "\n",
        "# Also aggregate inverter actual energy if useful\n",
        "inv_energy_cols = [\n",
        "    \"actual_inv1_energy_MWh\",\n",
        "    \"actual_inv2_energy_MWh\"\n",
        "]\n",
        "for col in inv_energy_cols:\n",
        "    if col in df.columns:\n",
        "        inv_id = col.split(\"_\")[2]  # e.g. 'inv1', 'inv2'\n",
        "        total = df[col].sum()\n",
        "        inv_agg.append({\n",
        "            \"inverter\": inv_id,\n",
        "            \"loss_type\": \"actual_energy\",\n",
        "            \"loss_MWh\": total\n",
        "        })\n",
        "\n",
        "if inv_agg:\n",
        "    inverter_losses = pd.DataFrame(inv_agg)\n",
        "    inverter_losses.to_csv(\"inverter_level_energy_losses.csv\", index=False)\n",
        "    print(\"Inverter-level losses saved as inverter_level_energy_losses.csv\")\n",
        "else:\n",
        "    print(\"No inverter-level loss columns found!\")\n",
        "\n",
        "\n",
        "# --- 3. STRING MISMATCH (AGGREGATE & TIME SERIES) ---\n",
        "# These are not per-string but describe string mismatch for the plant as a whole.\n",
        "\n",
        "string_mismatch_loss_col = \"string_mismatch_loss_MWh\"\n",
        "string_mismatch_frac_col = \"string_mismatch_loss_frac\"\n",
        "string_current_mean_col = \"string_current_mean\"\n",
        "string_current_std_col = \"string_current_std\"\n",
        "\n",
        "agg_string_losses = {\n",
        "    \"total_string_mismatch_loss_MWh\": df[string_mismatch_loss_col].sum() if string_mismatch_loss_col in df.columns else None,\n",
        "    \"avg_string_current_std\": df[string_current_std_col].mean() if string_current_std_col in df.columns else None,\n",
        "    \"max_string_current_std\": df[string_current_std_col].max() if string_current_std_col in df.columns else None,\n",
        "    \"avg_string_mismatch_loss_frac\": df[string_mismatch_frac_col].mean() if string_mismatch_frac_col in df.columns else None,\n",
        "}\n",
        "string_mismatch_summary = pd.DataFrame([agg_string_losses])\n",
        "string_mismatch_summary.to_csv(\"string_mismatch_plant_summary.csv\", index=False)\n",
        "\n",
        "# Save time series for string mismatch loss and current std (optional for further analysis)\n",
        "string_ts_cols = []\n",
        "for col in [string_mismatch_loss_col, string_current_std_col, string_current_mean_col, string_mismatch_frac_col]:\n",
        "    if col in df.columns:\n",
        "        string_ts_cols.append(col)\n",
        "\n",
        "# Try to add a time column if present\n",
        "for tcol in [\"datetime\", \"hour\", \"timestamp\"]:\n",
        "    if tcol in df.columns:\n",
        "        time_col = tcol\n",
        "        break\n",
        "else:\n",
        "    time_col = None\n",
        "\n",
        "if time_col:\n",
        "    string_ts_cols = [time_col] + string_ts_cols\n",
        "\n",
        "if string_ts_cols:\n",
        "    df[string_ts_cols].to_csv(\"string_mismatch_timeseries.csv\", index=False)\n",
        "\n",
        "# --- 4. STRING LEVEL (if per-string columns exist) ---\n",
        "# For demonstration, search for all columns ending in \"_stringXX\"\n",
        "string_loss_pattern = re.compile(r'(.+)_string(\\d+)$')\n",
        "string_loss_entries = []\n",
        "\n",
        "for col in df.columns:\n",
        "    match = string_loss_pattern.match(col)\n",
        "    if match:\n",
        "        loss_type, string_id = match.groups()\n",
        "        total = df[col].sum()\n",
        "        string_loss_entries.append({\"string\": string_id, \"loss_type\": loss_type, \"loss_MWh\": total})\n",
        "\n",
        "if string_loss_entries:\n",
        "    string_losses = pd.DataFrame(string_loss_entries)\n",
        "    string_losses.to_csv(\"string_level_energy_losses.csv\", index=False)\n",
        "    print(\"String-level losses saved as string_level_energy_losses.csv\")\n",
        "# else:\n",
        "#     print(\"No string-level loss columns found.\")\n",
        "\n",
        "# --- 5. Print summary ---\n",
        "print(\"Plant-level losses saved as plant_level_energy_losses.csv\")\n",
        "print(\"Inverter-level losses saved as inverter_level_energy_losses.csv\")\n",
        "print(\"Plant-level string mismatch summary saved as string_mismatch_plant_summary.csv\")\n",
        "if string_ts_cols:\n",
        "    print(\"String mismatch timeseries saved as string_mismatch_timeseries.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnC5XuEYPr3U",
        "outputId": "f7d83634-8be2-4cd6-ac80-e900e4ca6708"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inverter-level losses saved as inverter_level_energy_losses.csv\n",
            "Plant-level losses saved as plant_level_energy_losses.csv\n",
            "Inverter-level losses saved as inverter_level_energy_losses.csv\n",
            "Plant-level string mismatch summary saved as string_mismatch_plant_summary.csv\n",
            "String mismatch timeseries saved as string_mismatch_timeseries.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loss boolean flags"
      ],
      "metadata": {
        "id": "NgtWh9n5G9l3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "flag_cols = ['cloud_loss_MWh', 'shading_loss_MWh', 'temp_loss_MWh', 'soiling_loss_MWh', 'unexplained_loss_MWh']\n",
        "threshold = 0.01  # set your threshold\n",
        "\n",
        "flags = pd.DataFrame()\n",
        "flags['datetime'] = df['datetime']\n",
        "for col in flag_cols:\n",
        "    if col in df.columns:\n",
        "        flags[col.replace('_MWh', '') + '_flag'] = (df[col] > threshold).astype(int)\n",
        "\n",
        "flags.to_csv('loss_boolean_flags_15min.csv', index=False)"
      ],
      "metadata": {
        "id": "Gum2c6Vy7-_L"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Daily, Weekly and Monthly loss calculation"
      ],
      "metadata": {
        "id": "4w5oB6REHFnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Assuming df is loaded from \"full_analysis_data.csv\"\n",
        "# Convert 'datetime' column to datetime objects\n",
        "df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "\n",
        "daily_losses = df.groupby(df['datetime'].dt.date)[loss_cols].sum()\n",
        "daily_losses.to_csv('losses_daily.csv')\n",
        "\n",
        "# Weekly\n",
        "df['week'] = df['datetime'].dt.to_period('W').astype(str)\n",
        "weekly_losses = df.groupby('week')[loss_cols].sum()\n",
        "weekly_losses.to_csv('losses_weekly.csv')\n",
        "\n",
        "# Monthly\n",
        "df['month_period'] = df['datetime'].dt.to_period('M').astype(str)\n",
        "monthly_losses = df.groupby('month_period')[loss_cols].sum()\n",
        "monthly_losses.to_csv('losses_monthly.csv')"
      ],
      "metadata": {
        "id": "wS5pywvinjma"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Estimate of per sting currents"
      ],
      "metadata": {
        "id": "nCk_2do6BOZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Select all string current columns\n",
        "string_current_cols = [col for col in df.columns if '_pv_i' in col]\n",
        "\n",
        "# Get statistics per string\n",
        "string_stats = df[string_current_cols].agg(['mean', 'std', 'min', 'max']).T.reset_index()\n",
        "string_stats.columns = ['string_column', 'mean', 'std', 'min', 'max']\n",
        "string_stats.to_csv('string_current_stats.csv', index=False)"
      ],
      "metadata": {
        "id": "EwdfnxzO99uz"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Estimation of String-Level Mismatch Loss Allocation Based on Current Imbalance"
      ],
      "metadata": {
        "id": "q4qw9CFJClIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'datetime' in df.columns:\n",
        "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "\n",
        "string_current_cols = [col for col in df.columns if '_pv_i' in col]  # all string current columns\n",
        "\n",
        "per_string_loss_entries = []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    currents = row[string_current_cols].values.astype(float)\n",
        "    mean_current = np.mean(currents)\n",
        "    deviations = np.abs(currents - mean_current)\n",
        "    total_deviation = deviations.sum()\n",
        "    if total_deviation > 0:\n",
        "        allocations = deviations / total_deviation\n",
        "    else:\n",
        "        allocations = np.zeros_like(deviations)\n",
        "    # Get the plant-level mismatch loss for this interval\n",
        "    mismatch_loss = 0\n",
        "    if 'string_mismatch_loss_MWh' in row and not pd.isna(row['string_mismatch_loss_MWh']):\n",
        "        mismatch_loss = row['string_mismatch_loss_MWh']\n",
        "    elif 'mismatch_loss_MWh' in row and not pd.isna(row['mismatch_loss_MWh']):\n",
        "        mismatch_loss = row['mismatch_loss_MWh']\n",
        "    # Allocate loss per string\n",
        "    per_string_loss = allocations * mismatch_loss\n",
        "    for i, col in enumerate(string_current_cols):\n",
        "        per_string_loss_entries.append({\n",
        "            'datetime': row['datetime'] if 'datetime' in row else idx,\n",
        "            'string_id': col,\n",
        "            'estimated_mismatch_loss_MWh': per_string_loss[i]\n",
        "        })\n",
        "\n",
        "per_string_loss_df = pd.DataFrame(per_string_loss_entries)\n",
        "per_string_loss_df.to_csv(\"per_string_mismatch_loss_timeseries.csv\", index=False)\n",
        "print(\"Saved per-string mismatch loss time series to per_string_mismatch_loss_timeseries.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMNmK51ZAbhQ",
        "outputId": "b491f30f-fdfc-42b3-a7aa-943f836d1da4"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved per-string mismatch loss time series to per_string_mismatch_loss_timeseries.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prediction of Theoretical and Actual Generation and Comparison with Corresponding Calculated Values"
      ],
      "metadata": {
        "id": "eqarD1SdJE3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"full_analysis_data.csv\")\n",
        "\n",
        "# --- 1. Define features and targets ---\n",
        "# Theoretical generation model\n",
        "features_theoretical = [\n",
        "    \"G_POA\", \"T_mod\", \"ghi_measured\", \"ghi_clearsky\", \"month\", \"hour\"\n",
        "]\n",
        "target_theoretical = \"E_theoretical_kWh\"\n",
        "\n",
        "# Actual generation model\n",
        "features_actual = features_theoretical + [\n",
        "    \"soiling_loss_MWh\", \"cloud_loss_MWh\", \"temp_loss_MWh\", \"tracker_loss_MWh\",\n",
        "    \"inverter_loss_MWh\", \"dc_wiring_loss_MWh\", \"shading_loss_MWh\", \"mismatch_loss_MWh\"\n",
        "]\n",
        "target_actual = \"actual_plant_energy_MWh\"\n",
        "\n",
        "# --- 2. Drop rows with missing values in used columns\n",
        "df_theo = df[features_theoretical + [target_theoretical]].dropna()\n",
        "df_act = df[features_actual + [target_actual]].dropna()\n",
        "\n",
        "# --- 3. Split data ---\n",
        "X_train_theo, X_test_theo, y_train_theo, y_test_theo = train_test_split(\n",
        "    df_theo[features_theoretical], df_theo[target_theoretical], test_size=0.2, random_state=42\n",
        ")\n",
        "X_train_act, X_test_act, y_train_act, y_test_act = train_test_split(\n",
        "    df_act[features_actual], df_act[target_actual], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# --- 4. Train models ---\n",
        "model_theo = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model_theo.fit(X_train_theo, y_train_theo)\n",
        "pred_theo = model_theo.predict(X_test_theo)\n",
        "\n",
        "model_act = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model_act.fit(X_train_act, y_train_act)\n",
        "pred_act = model_act.predict(X_test_act)\n",
        "\n",
        "# --- 5. Evaluate models ---\n",
        "print(\"Theoretical Gen Model: R2 =\", r2_score(y_test_theo, pred_theo), \"MAE =\", mean_absolute_error(y_test_theo, pred_theo))\n",
        "print(\"Actual Gen Model:      R2 =\", r2_score(y_test_act, pred_act), \"MAE =\", mean_absolute_error(y_test_act, pred_act))\n",
        "\n",
        "# --- 6. Compare with calculated values and plot ---\n",
        "# Theoretical Generation: predicted vs. calculated\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.scatter(y_test_theo, pred_theo, alpha=0.5, label='Prediction')\n",
        "plt.plot([y_test_theo.min(), y_test_theo.max()], [y_test_theo.min(), y_test_theo.max()], 'r--', label='Ideal')\n",
        "plt.xlabel('Calculated Theoretical (kWh)')\n",
        "plt.ylabel('Predicted Theoretical (kWh)')\n",
        "plt.title('Theoretical Generation\\nPrediction vs. Actual')\n",
        "plt.legend()\n",
        "\n",
        "# Actual Generation: predicted vs. calculated\n",
        "plt.subplot(1,2,2)\n",
        "plt.scatter(y_test_act, pred_act, alpha=0.5, label='Prediction')\n",
        "plt.plot([y_test_act.min(), y_test_act.max()], [y_test_act.min(), y_test_act.max()], 'r--', label='Ideal')\n",
        "plt.xlabel('Calculated Actual (MWh)')\n",
        "plt.ylabel('Predicted Actual (MWh)')\n",
        "plt.title('Actual Generation\\nPrediction vs. Actual')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- 7. Time series comparison for a sample (if you have a time column, e.g. 'hour' or 'datetime') ---\n",
        "# You can plot a slice by index or by time\n",
        "if \"hour\" in df.columns:\n",
        "    # plt.figure(figsize=(12,4))\n",
        "    # idx = X_test_theo.index[:100]\n",
        "    # plt.plot(df.loc[idx, \"hour\"], y_test_theo.loc[idx], label=\"Theoretical Actual\")\n",
        "    # plt.plot(df.loc[idx, \"hour\"], pred_theo[:100], label=\"Theoretical Predicted\")\n",
        "    # plt.plot(df.loc[idx, \"hour\"], y_test_act.loc[idx], label=\"Actual Actual\")\n",
        "    # plt.plot(df.loc[idx, \"hour\"], pred_act[:100], label=\"Actual Predicted\")\n",
        "    # plt.xlabel(\"Hour\")\n",
        "    # plt.ylabel(\"Generation\")\n",
        "    # plt.title(\"Generation Comparison (Sample 100)\")\n",
        "    # plt.legend()\n",
        "    # plt.show()\n",
        "    # Option 1: Use .iloc to plot the first 100 samples from each test set\n",
        "    plt.figure(figsize=(12,4))\n",
        "    n = min(100, len(y_test_theo), len(y_test_act))  # in case test sets are small\n",
        "\n",
        "    # Theoretical\n",
        "    plt.plot(range(n), y_test_theo.iloc[:n], label=\"Theoretical Actual\")\n",
        "    plt.plot(range(n), pred_theo[:n], label=\"Theoretical Predicted\")\n",
        "\n",
        "    # Actual\n",
        "    plt.plot(range(n), y_test_act.iloc[:n], label=\"Actual Actual\")\n",
        "    plt.plot(range(n), pred_act[:n], label=\"Actual Predicted\")\n",
        "\n",
        "    plt.xlabel(\"Sample Index\")\n",
        "    plt.ylabel(\"Generation\")\n",
        "    plt.title(\"Generation Comparison (First {} Test Samples)\".format(n))\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViKuENL6Ja_w",
        "outputId": "99fa6ef6-2535-44e4-bd7a-44666a5f2409"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theoretical Gen Model: R2 = 0.99995191491369 MAE = 6.42958575696794\n",
            "Actual Gen Model:      R2 = 0.9367899771356037 MAE = 0.05328755508849305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Daily loss breakdown"
      ],
      "metadata": {
        "id": "dKFvdv2-Jupd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv(\"full_analysis_data.csv\", parse_dates=['datetime'])\n",
        "loss_cols = ['cloud_loss_MWh', 'shading_loss_MWh', 'temp_loss_MWh', 'soiling_loss_MWh', 'unexplained_loss_MWh']\n",
        "\n",
        "# Stacked bar of daily loss breakdown\n",
        "daily_losses = df.groupby(df['datetime'].dt.date)[loss_cols].sum()\n",
        "daily_losses.plot(kind='bar', stacked=True, figsize=(14,6))\n",
        "plt.title('Daily Loss Breakdown by Class')\n",
        "plt.ylabel('Energy Loss (MWh)')\n",
        "plt.xlabel('Date')\n",
        "plt.tight_layout()\n",
        "plt.savefig('daily_loss_breakdown.png')\n",
        "plt.show()\n",
        "\n",
        "# Asset ranking (e.g., by total unexplained loss, if inverter-level data exists)\n",
        "if 'unexplained_loss_inv1_MWh' in df.columns and 'unexplained_loss_inv2_MWh' in df.columns:\n",
        "    asset_ranking = {\n",
        "        'inv1': df['unexplained_loss_inv1_MWh'].sum(),\n",
        "        'inv2': df['unexplained_loss_inv2_MWh'].sum()\n",
        "    }\n",
        "    pd.Series(asset_ranking).sort_values(ascending=False).plot(kind='bar')\n",
        "    plt.title('Inverter Asset Ranking by Unexplained Loss')\n",
        "    plt.ylabel('Total Unexplained Loss (MWh)')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('inverter_asset_ranking.png')\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "sA6FIIENC9Uw"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Final loss summary"
      ],
      "metadata": {
        "id": "BDSp84TsJzBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_cols = [\n",
        "    'cloud_loss_MWh', 'temp_loss_MWh', 'soiling_loss_MWh', 'shading_loss_MWh',\n",
        "    'inverter_loss_MWh', 'dc_wiring_loss_MWh', 'mismatch_loss_MWh',\n",
        "    'tracker_loss_MWh', 'high_wind_loss', 'humidity_loss', 'unexplained_loss_MWh'\n",
        "]\n",
        "summary = df[loss_cols].sum().sort_values(ascending=False)\n",
        "summary.to_csv('final_loss_summary.csv')"
      ],
      "metadata": {
        "id": "_pivujIYKgdL"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summary of the tables generated"
      ],
      "metadata": {
        "id": "zHzgZ-uXJ98p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "csv_files = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
        "print(\"CSV files in current directory:\")\n",
        "for f in csv_files:\n",
        "    print(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6LR4YUCL3um",
        "outputId": "e57cfe16-213c-477c-daa5-511192721d76"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV files in current directory:\n",
            "plant_level_energy_losses.csv\n",
            "asset_ranking_unexplained_loss.csv\n",
            "per_string_mismatch_loss_timeseries.csv\n",
            "losses_daily.csv\n",
            "inverter_level_energy_losses.csv\n",
            "asset_ranking_all_losses.csv\n",
            "string_current_stats.csv\n",
            "string_mismatch_timeseries.csv\n",
            "string_mismatch_plant_summary.csv\n",
            "final_loss_summary.csv\n",
            "loss_boolean_flags_15min.csv\n",
            "losses_monthly.csv\n",
            "losses_weekly.csv\n",
            "full_analysis_data.csv\n",
            "boolean_loss_flags_full.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dashboard generation"
      ],
      "metadata": {
        "id": "eq5Wp7sDKElA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load your main data\n",
        "df = pd.read_csv(\"full_analysis_data.csv\", parse_dates=['datetime'])\n",
        "\n",
        "# Update this list to only include present columns and keep order:\n",
        "loss_cols = [\n",
        "    'cloud_loss_MWh', 'temp_loss_MWh', 'soiling_loss_MWh', 'shading_loss_MWh',\n",
        "    'inverter_loss_MWh', 'dc_wiring_loss_MWh', 'mismatch_loss_MWh',\n",
        "    'tracker_loss_MWh', 'high_wind_loss', 'humidity_loss', 'unexplained_loss_MWh'\n",
        "]\n",
        "loss_cols = [col for col in loss_cols if col in df.columns]\n",
        "\n",
        "# Asset columns\n",
        "asset_loss_cols = [col for col in df.columns if (\"_inv\" in col or \"_string\" in col) and col.endswith(\"_MWh\")]\n",
        "\n",
        "def loss_pie_chart():\n",
        "    fig, ax = plt.subplots()\n",
        "    loss_sum = df[loss_cols].sum()\n",
        "    colors = ['skyblue', 'orange', 'limegreen', 'gray', 'violet', 'gold', 'purple',\n",
        "              'olive', 'lightgreen', 'lightblue', 'red']\n",
        "    ax.pie(loss_sum, labels=loss_cols, colors=colors[:len(loss_cols)], autopct='%1.1f%%')\n",
        "    ax.set_title(\"Loss Breakdown (Pie Chart)\")\n",
        "    return fig\n",
        "\n",
        "def losses_over_time(freq):\n",
        "    fig, ax = plt.subplots(figsize=(11, 5))\n",
        "    df2 = df.set_index('datetime')[loss_cols].resample(freq).sum()\n",
        "    df2.plot(ax=ax)\n",
        "    ax.set_title(f\"Losses Over Time ({freq})\")\n",
        "    ax.set_ylabel(\"Loss (MWh)\")\n",
        "    ax.set_xlabel(\"Date\")\n",
        "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def performance_ratio_analysis():\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Work on a copy\n",
        "    dfx = df.copy()\n",
        "\n",
        "    # Make sure PR exists\n",
        "    if 'PR' not in dfx.columns:\n",
        "        # Try to calculate if possible, else display error\n",
        "        if 'actual_plant_energy_MWh' in dfx.columns and 'P_theoretical_energy_MWh' in dfx.columns:\n",
        "            dfx['PR'] = (dfx['actual_plant_energy_MWh'] / dfx['P_theoretical_energy_MWh']).clip(0, 1.2)\n",
        "        else:\n",
        "            fig, ax = plt.subplots()\n",
        "            ax.text(0.5, 0.5, 'Missing PR and energy columns', ha='center', va='center')\n",
        "            return fig\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "    # PR by hour of day\n",
        "    if 'hour' in dfx.columns:\n",
        "        pr_hour = dfx.groupby('hour')['PR'].mean()\n",
        "        axes[0,0].plot(pr_hour.index, pr_hour.values, marker='o')\n",
        "        axes[0,0].set_title('PR by Hour of Day')\n",
        "        axes[0,0].set_ylim(0, 1.1)\n",
        "        axes[0,0].set_xlabel('Hour')\n",
        "        axes[0,0].set_ylabel('PR')\n",
        "    else:\n",
        "        axes[0,0].text(0.5, 0.5, 'No hour data', ha='center', va='center')\n",
        "\n",
        "    # PR by temperature range\n",
        "    if 'T_mod' in dfx.columns:\n",
        "        temp_bins = [0, 20, 40, 60, 80]\n",
        "        temp_range = pd.cut(dfx['T_mod'], bins=temp_bins)\n",
        "        dfx2 = dfx.copy()\n",
        "        dfx2['temp_range'] = temp_range\n",
        "        pr_temp = dfx2.groupby('temp_range')['PR'].mean()\n",
        "        axes[0,1].bar([str(x) for x in pr_temp.index], pr_temp.values)\n",
        "        axes[0,1].set_title('PR by Temperature Range')\n",
        "        axes[0,1].set_ylim(0, 1.1)\n",
        "        axes[0,1].set_xlabel('Temperature Range')\n",
        "        axes[0,1].set_ylabel('PR')\n",
        "    else:\n",
        "        axes[0,1].text(0.5, 0.5, 'No T_mod data', ha='center', va='center')\n",
        "\n",
        "    # PR histogram\n",
        "    dfx['PR'].dropna().hist(ax=axes[1,0], bins=30)\n",
        "    axes[1,0].set_title('PR Distribution')\n",
        "    axes[1,0].set_xlabel('PR')\n",
        "    axes[1,0].set_ylabel('Frequency')\n",
        "\n",
        "    # PR trend over time\n",
        "    if 'datetime' in dfx.columns and pd.api.types.is_datetime64_any_dtype(dfx['datetime']):\n",
        "        dfx_time = dfx.set_index('datetime')\n",
        "        pr_trend = dfx_time['PR'].resample('W').mean()\n",
        "        axes[1,1].plot(pr_trend.index, pr_trend.values)\n",
        "        axes[1,1].set_title('Weekly PR Trend')\n",
        "        axes[1,1].axhline(0.8, color='red', linestyle='--')\n",
        "        axes[1,1].set_xlabel('Date')\n",
        "        axes[1,1].set_ylabel('PR')\n",
        "    else:\n",
        "        axes[1,1].text(0.5, 0.5, 'No datetime data', ha='center', va='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "def asset_ranking(col):\n",
        "    if col not in df.columns:\n",
        "        return f\"Column {col} not found in data.\"\n",
        "    ranking = df[col]\n",
        "    fig, ax = plt.subplots(figsize=(9, 4))\n",
        "    ranking.plot(kind='hist', ax=ax, bins=30)\n",
        "    ax.set_title(f\"Distribution: {col}\")\n",
        "    ax.set_ylabel(\"Frequency\")\n",
        "    ax.set_xlabel(col)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def loss_flags_table():\n",
        "    flag_cols = [col for col in df.columns if col.endswith('_flag')]\n",
        "    if not flag_cols:\n",
        "        return pd.DataFrame({'info': ['No flag columns found.']})\n",
        "    cols = ['datetime'] + [c for c in ['Zone', 'INVERTER', 'String'] if c in df.columns] + flag_cols\n",
        "    out = df[cols].copy()\n",
        "    return out.head(100)  # Only show first 100 rows for brevity\n",
        "\n",
        "def correlation_heatmap():\n",
        "    corr_cols = loss_cols + [c for c in ['G_POA', 'T_mod', 'actual_plant_power_MW', 'PR'] if c in df.columns]\n",
        "    corr = df[corr_cols].corr()\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", ax=ax)\n",
        "    ax.set_title(\"Correlation Heatmap: Losses and Key Metrics\")\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# ☀️ Solar PV Loss Attribution Dashboard\")\n",
        "    gr.Markdown(\"Explore and interact with your plant's loss data. Select a visualization below.\")\n",
        "    with gr.Tab(\"Loss Breakdown Pie\"):\n",
        "        gr.Plot(loss_pie_chart)\n",
        "    with gr.Tab(\"Losses Over Time\"):\n",
        "        freq = gr.Radio(['W', 'D', 'M'], label=\"Frequency\", value='W')\n",
        "        gr.Plot(losses_over_time, inputs=[freq])\n",
        "    with gr.Tab(\"Performance Ratio Analysis\"):\n",
        "        gr.Plot(performance_ratio_analysis)\n",
        "    with gr.Tab(\"Asset Loss Distribution\"):\n",
        "        asset_col = gr.Dropdown(asset_loss_cols, label=\"Asset loss column\", value=asset_loss_cols[0] if asset_loss_cols else None)\n",
        "        gr.Plot(asset_ranking, inputs=[asset_col])\n",
        "    with gr.Tab(\"Loss Flags Table\"):\n",
        "        gr.Dataframe(loss_flags_table)\n",
        "    with gr.Tab(\"Correlation Heatmap\"):\n",
        "        gr.Plot(correlation_heatmap)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "eGZrGm3KP3PC",
        "outputId": "5e4c9c12-fcd9-48f1-8397-a6b87f1a1504"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://52a4c67a7533b328b0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://52a4c67a7533b328b0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LLM-powered executive report"
      ],
      "metadata": {
        "id": "Xf7EId8_KOGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# --- 1. Load all CSVs you have ---\n",
        "csv_paths = {\n",
        "    'full_analysis': 'full_analysis_data.csv',\n",
        "    'plant_loss': 'plant_level_energy_losses.csv',\n",
        "    'inverter_loss': 'inverter_level_energy_losses.csv',\n",
        "    'string_mismatch_summary': 'string_mismatch_plant_summary.csv',\n",
        "    'string_mismatch_timeseries': 'string_mismatch_timeseries.csv',\n",
        "    'per_string_mismatch_timeseries': 'per_string_mismatch_loss_timeseries.csv',\n",
        "    'string_current_stats': 'string_current_stats.csv',\n",
        "    'bool_flags_full': 'boolean_loss_flags_full.csv',\n",
        "    'loss_flags_15min': 'loss_boolean_flags_15min.csv',\n",
        "    'final_loss_summary': 'final_loss_summary.csv',\n",
        "    'losses_weekly': 'losses_weekly.csv',\n",
        "    'losses_monthly': 'losses_monthly.csv',\n",
        "    'losses_daily': 'losses_daily.csv',\n",
        "    'asset_ranking_all': 'asset_ranking_all_losses.csv',\n",
        "    'asset_ranking_unexpl': 'asset_ranking_unexplained_loss.csv'\n",
        "}\n",
        "\n",
        "dfs = {k: pd.read_csv(v) for k, v in csv_paths.items() if os.path.exists(v)}\n",
        "\n",
        "# --- 2. Key columns (update if needed) ---\n",
        "datetime_col = \"hour\"\n",
        "gen_col = \"actual_plant_energy_MWh\"\n",
        "theoretical_col = \"P_theoretical_energy_MWh\"\n",
        "pr_col = \"PR\"\n",
        "unexpl_col = \"unexplained_loss_MWh\"\n",
        "soiling_col = \"soiling_loss_MWh\"\n",
        "cloud_col = \"cloud_loss_MWh\"\n",
        "temp_col = \"temp_loss_MWh\"\n",
        "tracker_col = \"tracker_loss_MWh\"\n",
        "inv_loss_col = \"inverter_loss_MWh\"\n",
        "dc_loss_col = \"dc_wiring_loss_MWh\"\n",
        "shading_col = \"shading_loss_MWh\"\n",
        "mismatch_col = \"mismatch_loss_MWh\"\n",
        "\n",
        "# --- 3. Compute summary statistics from main data ---\n",
        "df_full = dfs['full_analysis']\n",
        "summary_text = f\"\"\"\n",
        "Period: {df_full[datetime_col].min()} to {df_full[datetime_col].max()}\n",
        "Total Actual Generation: {df_full[gen_col].sum():.2f} MWh\n",
        "Theoretical Generation: {df_full[theoretical_col].sum():.2f} MWh\n",
        "Performance Ratio (avg): {df_full[pr_col].mean():.3f}\n",
        "Known Losses (MWh):\n",
        "  - Soiling: {df_full[soiling_col].sum():.2f}\n",
        "  - Cloud: {df_full[cloud_col].sum():.2f}\n",
        "  - Temp: {df_full[temp_col].sum():.2f}\n",
        "  - Tracker: {df_full[tracker_col].sum():.2f}\n",
        "  - Inverter: {df_full[inv_loss_col].sum():.2f}\n",
        "  - DC Wiring: {df_full[dc_loss_col].sum():.2f}\n",
        "  - Shading: {df_full[shading_col].sum():.2f}\n",
        "  - String Mismatch: {df_full[mismatch_col].sum():.2f}\n",
        "Unexplained Loss (total): {df_full[unexpl_col].sum():.2f} MWh ({(df_full[unexpl_col].sum()/df_full[theoretical_col].sum()*100):.1f}% of theoretical)\n",
        "Highest unexplained loss (interval): {df_full[unexpl_col].max():.2f} MWh at {df_full.loc[df_full[unexpl_col].idxmax(), datetime_col]}\n",
        "\"\"\"\n",
        "\n",
        "# --- 4. Top assets by total loss and unexplained loss ---\n",
        "all_losses = dfs['asset_ranking_all']\n",
        "unexpl = dfs['asset_ranking_unexpl']\n",
        "summary_text += f\"\\nTop 5 assets by total loss:\\n{all_losses.head(5).to_string(index=False)}\\n\"\n",
        "summary_text += f\"\\nTop 5 assets by unexplained loss:\\n{unexpl.head(5).to_string(index=False)}\\n\"\n",
        "\n",
        "# --- 5. Add event statistics from full boolean flags table ---\n",
        "bool_flags = dfs['bool_flags_full']\n",
        "flag_sums = bool_flags.sum(numeric_only=True)\n",
        "summary_text += f\"\\nLoss event counts (boolean flags, all assets summed):\\n{flag_sums.to_string()}\\n\"\n",
        "\n",
        "# --- 6. Add more summaries from other files as desired ---\n",
        "if 'plant_loss' in dfs:\n",
        "    plant_loss_summary = dfs['plant_loss'].describe().to_string()\n",
        "    summary_text += f\"\\nPlant-level loss summary:\\n{plant_loss_summary}\\n\"\n",
        "if 'final_loss_summary' in dfs:\n",
        "    summary_text += f\"\\nFinal loss summary:\\n{dfs['final_loss_summary'].to_string(index=False)}\\n\"\n",
        "if 'string_mismatch_summary' in dfs:\n",
        "    summary_text += f\"\\nString mismatch plant summary (top 5):\\n{dfs['string_mismatch_summary'].head(5).to_string(index=False)}\\n\"\n",
        "if 'string_current_stats' in dfs:\n",
        "    summary_text += f\"\\nString current stats (top 5):\\n{dfs['string_current_stats'].head(5).to_string(index=False)}\\n\"\n",
        "\n",
        "# --- 7. Prepare the LLM prompt ---\n",
        "\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are a solar plant analyst.\n",
        "\n",
        "Given the following comprehensive summary from all plant CSVs, generate a clear, concise executive report with the following deliverables:\n",
        "\n",
        "DELIVERABLES:\n",
        "• A report/dashboard with:\n",
        "  - Theoretical generation (model-based) summary.\n",
        "  - Actual vs. theoretical generation comparison (numerical values, visual/graphical description).\n",
        "  - Boolean flags for each 15-min interval and each loss class (show sample table if space is limited).\n",
        "  - Quantified losses by class (soiling, cloud, temperature, tracker, inverter, DC wiring, shading, string mismatch, unexplained), for 15-min, hourly, daily, weekly, monthly, and at Plant, Inverter, and String levels. Add insights and reasoning. Use tables as needed.\n",
        "  - Asset ranking: best-performing, under-performing, high/medium soiling loss, and other significant loss categories.\n",
        "  - Table attributing losses for each asset (Asset Name, Loss Class, Total Loss MWh).\n",
        "  - Organize the report clearly with section headings and tables.\n",
        "  - Highlight major findings in simple, executive-friendly language.\n",
        "  - Identify any assets that need urgent O&M attention.\n",
        "  - Explain large unexplained losses and their possible causes.\n",
        "  - Give at least 2 actionable recommendations for plant improvement.\n",
        "\n",
        "Summary:\n",
        "{summary_text}\n",
        "\"\"\"\n",
        "\n",
        "# --- 8. OpenAI API key (set securely!) ---\n",
        "openai_api_key = os.environ.get(\"OPENAI_API_KEY\", '')  # Or set manually, but don't commit to code\n",
        "\n",
        "def generate_llm_report(prompt, openai_api_key):\n",
        "    client = openai.OpenAI(api_key=openai_api_key)\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=2500,\n",
        "        temperature=0.4\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "with open(\"solar_plant_report.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(report)\n",
        "\n",
        "# --- 9. Run and print report ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Generating LLM-powered executive report...\\n\")\n",
        "    if not openai_api_key:\n",
        "        print(\"OpenAI API key not found. Please set your API key in the environment variable 'OPENAI_API_KEY'.\")\n",
        "    else:\n",
        "        report = generate_llm_report(prompt, openai_api_key)\n",
        "        print(\"----- Solar Plant Executive Report -----\\n\")\n",
        "        print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dp7fpLZXpDco",
        "outputId": "b38f57a8-1ede-4fe7-9122-821b5c677b64"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating LLM-powered executive report...\n",
            "\n",
            "----- Solar Plant Executive Report -----\n",
            "\n",
            "# Executive Solar Plant Performance Report  \n",
            "**Period:** 0 to 23 hours  \n",
            "**Plant:** [Name/ID withheld]  \n",
            "\n",
            "---\n",
            "\n",
            "## 1. Theoretical Generation Summary  \n",
            "- **Total Theoretical Generation:** 29,572.16 MWh  \n",
            "- This value represents the modeled maximum expected output under ideal conditions, accounting for irradiance, temperature, and system design parameters.\n",
            "\n",
            "---\n",
            "\n",
            "## 2. Actual vs. Theoretical Generation Comparison  \n",
            "\n",
            "| Metric                  | Value (MWh) | % of Theoretical |\n",
            "|-------------------------|-------------|------------------|\n",
            "| Actual Generation       | 5,011.90    | 16.96%           |\n",
            "| Theoretical Generation  | 29,572.16   | 100%             |\n",
            "| Performance Ratio (Avg) | 0.166       | 16.6%            |\n",
            "\n",
            "**Insight:**  \n",
            "The plant operated at only ~17% of its theoretical capacity, indicating significant losses and underperformance.\n",
            "\n",
            "**Visual Description:**  \n",
            "- A bar chart would show a tall bar for theoretical generation and a much smaller bar for actual generation, emphasizing the gap.  \n",
            "- A line graph of performance ratio over time would likely show consistently low values.\n",
            "\n",
            "---\n",
            "\n",
            "## 3. Losses Overview and Boolean Flags  \n",
            "\n",
            "### Total Losses by Class (MWh)  \n",
            "\n",
            "| Loss Class       | Total Loss (MWh) | % of Theoretical Generation |\n",
            "|------------------|------------------|-----------------------------|\n",
            "| Unexplained      | 10,397.14        | 35.2%                       |\n",
            "| String Mismatch  | 6,959.91         | 23.5%                       |\n",
            "| Cloud            | 4,813.76         | 16.3%                       |\n",
            "| Soiling          | 1,334.66         | 4.5%                        |\n",
            "| Temperature      | 954.69           | 3.2%                        |\n",
            "| Inverter         | 591.44           | 2.0%                        |\n",
            "| Shading          | 295.72           | 1.0%                        |\n",
            "| DC Wiring        | 295.72           | 1.0%                        |\n",
            "| Tracker          | 147.86           | 0.5%                        |\n",
            "| High Wind        | 0                | 0%                          |\n",
            "| Humidity         | 0                | 0%                          |\n",
            "\n",
            "---\n",
            "\n",
            "### Boolean Flags for Loss Events (Sample for 15-min intervals aggregated over all assets)  \n",
            "\n",
            "| Loss Class         | Number of Intervals with Loss Flag ON |\n",
            "|--------------------|---------------------------------------|\n",
            "| Cloud              | 1,574                                 |\n",
            "| Temperature        | 2,826                                 |\n",
            "| Soiling            | 739                                   |\n",
            "| Shading            | 3,487                                 |\n",
            "| Inverter           | 3,487                                 |\n",
            "| DC Wiring          | 3,487                                 |\n",
            "| String Mismatch    | 1,401                                 |\n",
            "| Tracker            | 3,487                                 |\n",
            "| Unexplained        | 2,664                                 |\n",
            "| High Wind          | 0                                     |\n",
            "| Humidity           | 0                                     |\n",
            "\n",
            "*Note: Each flag indicates presence of loss in the 15-min interval.*\n",
            "\n",
            "---\n",
            "\n",
            "## 4. Loss Quantification by Time Interval and Asset Level  \n",
            "\n",
            "### Plant-Level Loss Summary (MWh)  \n",
            "\n",
            "| Statistic  | Loss (MWh)          |\n",
            "|------------|---------------------|\n",
            "| Count      | 11 (days/weeks?)    |\n",
            "| Mean       | 2,344.63            |\n",
            "| Std Dev    | 3,499.75            |\n",
            "| Min        | 0                   |\n",
            "| 25th Pctl  | 221.79              |\n",
            "| Median     | 591.44              |\n",
            "| 75th Pctl  | 3,074.21            |\n",
            "| Max        | 10,397.14           |\n",
            "\n",
            "---\n",
            "\n",
            "### String Mismatch Loss Summary (Top 5 Strings)  \n",
            "\n",
            "| Metric                           | Value              |\n",
            "|---------------------------------|--------------------|\n",
            "| Total String Mismatch Loss (MWh)| 6,959.91           |\n",
            "| Avg String Current Std Dev       | 0.68               |\n",
            "| Max String Current Std Dev       | 11.67              |\n",
            "| Avg String Mismatch Loss Fraction| 0.167              |\n",
            "\n",
            "### String Current Statistics (Top 5 Strings)  \n",
            "\n",
            "| String ID                                  | Mean Current (A) | Std Dev (A) | Min (A) | Max (A)  |\n",
            "|--------------------------------------------|------------------|-------------|---------|----------|\n",
            "| inversores_ctin03_strings_string8_pv_i9    | 3.45             | 5.91        | 0.0     | 24.09    |\n",
            "| inversores_ctin03_strings_string8_pv_i13   | 3.33             | 5.73        | 0.0     | 23.31    |\n",
            "| inversores_ctin03_strings_string8_pv_i1    | 1.78             | 2.99        | 0.0     | 12.00    |\n",
            "| inversores_ctin03_strings_string8_pv_i6    | 3.63             | 6.14        | 0.0     | 24.55    |\n",
            "| inversores_ctin03_strings_string8_pv_i4    | 3.55             | 5.98        | 0.0     | 24.23    |\n",
            "\n",
            "---\n",
            "\n",
            "## 5. Asset Ranking and Loss Attribution  \n",
            "\n",
            "### Top 5 Assets by Total Loss (MWh)  \n",
            "\n",
            "| Asset | Unexplained | Soiling | Mismatch | Temp | Cloud | Tracker | Inverter | DC Wiring | Shading |\n",
            "|-------|-------------|---------|----------|------|-------|---------|----------|-----------|---------|\n",
            "| inv2  | 5,215.64    | 633.96  | 3,815.91 | 474.60 | 2,527.11 | 75.05   | 300.19   | 150.09    | 150.09  |\n",
            "| inv1  | 5,181.32    | 700.26  | 3,138.78 | 480.10 | 2,283.30 | 72.79   | 291.15   | 145.57    | 145.57  |\n",
            "\n",
            "**Note:** inv1 and inv2 dominate losses across all categories.\n",
            "\n",
            "---\n",
            "\n",
            "### Top 5 Assets by Unexplained Loss (MWh)  \n",
            "\n",
            "| Asset | Unexplained Loss (MWh) |\n",
            "|-------|------------------------|\n",
            "| inv2  | 5,215.64               |\n",
            "| inv1  | 5,181.32               |\n",
            "\n",
            "---\n",
            "\n",
            "## 6. Major Findings  \n",
            "\n",
            "- **Extremely Low Performance Ratio (16.6%)** indicates severe underperformance.  \n",
            "- **Unexplained losses are the largest loss category (35.2%)**, suggesting significant unknown issues or data/model mismatches.  \n",
            "- **String mismatch losses are substantial (23.5%)**, indicating possible electrical or module degradation issues.  \n",
            "- **Cloud losses (16.3%) and soiling (4.5%) are also significant**, pointing to environmental and maintenance factors.  \n",
            "- **Inverter-related losses are notable but smaller (~2%)**, with inv1 and inv2 showing the highest inverter and unexplained losses.  \n",
            "- **No high wind or humidity losses detected**, simplifying environmental loss considerations.  \n",
            "- **Loss event flags show frequent shading, inverter, DC wiring, and tracker losses**, indicating systemic issues with these components or layout.  \n",
            "\n",
            "---\n",
            "\n",
            "## 7. Assets Needing Urgent O&M Attention  \n",
            "\n",
            "- **Inverters inv1 and inv2**: Highest unexplained and mismatch losses, plus significant inverter and soiling losses.  \n",
            "- **Strings with high current variability and mismatch** (see String Current Stats) should be inspected for wiring faults, degradation, or shading.  \n",
            "\n",
            "---\n",
            "\n",
            "## 8. Explanation of Large Unexplained Losses  \n",
            "\n",
            "- Could be due to:  \n",
            "  - Sensor/data errors or missing data in the model inputs.  \n",
            "  - Unmodeled environmental factors (e.g., soiling hotspots, micro-shading).  \n",
            "  - Faulty modules or wiring not captured in mismatch or inverter losses.  \n",
            "  - Calibration errors in theoretical generation model.  \n",
            "  - Temporary outages or deratings not logged.  \n",
            "\n",
            "---\n",
            "\n",
            "## 9. Recommendations for Plant Improvement  \n",
            "\n",
            "1. **Conduct detailed inspection and maintenance on inverters inv1 and inv2**, focusing on wiring, cooling, and firmware updates to reduce inverter and unexplained losses.  \n",
            "2. **Perform string-level electrical testing and cleaning**, especially on strings with high current variability and mismatch losses, to identify and repair faulty modules or connections.  \n",
            "3. (Bonus) **Implement improved soiling monitoring and cleaning schedules** to reduce the 4.5% soiling losses, potentially improving performance ratio.  \n",
            "\n",
            "---\n",
            "\n",
            "## 10. Sample Loss Flag Table (15-min Interval Example)  \n",
            "\n",
            "| Interval | Cloud Loss Flag | Temp Loss Flag | Soiling Loss Flag | Shading Loss Flag | Inverter Loss Flag | DC Wiring Loss Flag | Mismatch Loss Flag | Tracker Loss Flag | Unexplained Loss Flag |\n",
            "|----------|-----------------|----------------|-------------------|-------------------|--------------------|---------------------|--------------------|-------------------|-----------------------|\n",
            "| 00:00    | True            | False          | False             | True              | True               | True                | False              | True              | True                  |\n",
            "| 00:15    | False           | True           | False             | False             | True               | True                | True               | True              | False                 |\n",
            "| 00:30    | True            | True           | True              | True              | False              | False               | True               | False             | True                  |\n",
            "| ...      | ...             | ...            | ...               | ...               | ...                | ...                 | ...                | ...               | ...                   |\n",
            "\n",
            "---\n",
            "\n",
            "# Summary  \n",
            "\n",
            "The plant is significantly underperforming, primarily due to large unexplained and string mismatch losses, with cloud and soiling also contributing. Two inverters (inv1 and inv2) are responsible for the majority of losses and require urgent inspection. Addressing these issues could substantially improve plant output and financial returns.\n",
            "\n",
            "---\n",
            "\n",
            "*Prepared by: Solar Plant Analyst*  \n",
            "*Date: [Insert Date]*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thanks"
      ],
      "metadata": {
        "id": "a5Lm7mSLKS21"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qMQLAySbwuZ3"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UMIun0tapKir"
      },
      "execution_count": 77,
      "outputs": []
    }
  ]
}